{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mwinga2\\AppData\\Local\\anaconda3\\envs\\REP\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import time\n",
    "\n",
    "import sys\n",
    "ROOT = \"../../\"\n",
    "sys.path.append(ROOT) # Add root directory to path\n",
    "\n",
    "from src.utils.perturbations import *\n",
    "from src.utils.REPResNet import Bottleneck, REPResNet\n",
    "\n",
    "from art.attacks.evasion import FastGradientMethod\n",
    "from art.estimators.classification import PyTorchClassifier\n",
    "from art.defences.preprocessor.preprocessor import PreprocessorPyTorch\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader, TensorDataset, Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Load the CIFAR-100 dataset\n",
    "trainset = datasets.CIFAR10(root='./data', train=True, download=True, transform=transforms.ToTensor())\n",
    "testset = datasets.CIFAR10(root='./data', train=False, download=True, transform=transforms.ToTensor())\n",
    "\n",
    "x_train = trainset.data / 255.0  # Scale pixel values to [0, 1]\n",
    "y_train = np.array(trainset.targets)\n",
    "\n",
    "x_test = testset.data / 255.0  # Scale pixel values to [0, 1]\n",
    "y_test = np.array(testset.targets)\n",
    "\n",
    "x_train = np.transpose(x_train, (0, 3, 1, 2)).astype(np.float32)\n",
    "x_test = np.transpose(x_test, (0, 3, 1, 2)).astype(np.float32)\n",
    "\n",
    "y_train = np.eye(100)[y_train].astype(np.float32)\n",
    "y_test = np.eye(100)[y_test].astype(np.float32)\n",
    "\n",
    "min_pixel_value = 0.0\n",
    "max_pixel_value = 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class REPPreprocessor(PreprocessorPyTorch):\n",
    "    def __init__(self, perturbations, include_original=True, shuffle=False):\n",
    "        super(REPPreprocessor, self).__init__()\n",
    "        self.perturbations = perturbations\n",
    "        self.include_original = include_original\n",
    "        self.shuffle = shuffle\n",
    "        self.multiplicity = len(self.perturbations) + int(self.include_original)\n",
    "\n",
    "    def forward(self, x, y=None):\n",
    "        # Apply perturbations to the input batch\n",
    "        x = x.to(self.device)\n",
    "        B, C, H, W = x.size()  # batch size, channels, height, width\n",
    "\n",
    "        # Apply perturbations to the input\n",
    "        layers = [x]\n",
    "        if not self.include_original:\n",
    "            layers = []\n",
    "\n",
    "        for perturbation in self.perturbations:\n",
    "            layers.append(perturbation(x))\n",
    "\n",
    "        if self.shuffle:\n",
    "            permutation = torch.randperm(len(layers))\n",
    "            layers = [layers[i] for i in permutation]\n",
    "\n",
    "        # Concatenate the perturbations along the channel dimension\n",
    "        perturbed_x = torch.cat(layers, dim=1)  # shape (B, multiplicity * C, H, W)\n",
    "\n",
    "        return perturbed_x, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing Round 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "perturbation_tests = [\n",
    "    [],\n",
    "    [[\"Gaussian\", 0.025]],\n",
    "    [[\"Gaussian\", 0.05]],\n",
    "    [[[\"Gaussian\", 0.05], [\"ContrastBrightness\", 0.9, 0.9]]],\n",
    "    [[[\"Gaussian\", 0.05], [\"RotationFlip\", 0.3]]],\n",
    "    [[[\"Gaussian\", 0.05], [\"SaltPepper\", 0.05]]],\n",
    "    [[\"Laplacian\", 0.025]],\n",
    "    [[\"Laplacian\", 0.05]],\n",
    "    [[[\"Laplacian\", 0.05], [\"ContrastBrightness\", 0.9, 0.9]]],\n",
    "    [[[\"Laplacian\", 0.05], [\"RotationFlip\", 0.3]]],\n",
    "    [[[\"Laplacian\", 0.05], [\"SaltPepper\", 0.05]]],\n",
    "    [[\"Lp-norm\", 0.5, 1]],\n",
    "    [[[\"Lp-norm\", 0.5, 1], [\"ContrastBrightness\", 0.9, 0.9]]],\n",
    "    [[[\"Lp-norm\", 0.5, 1], [\"RotationFlip\", 0.3]]],\n",
    "    [[[\"Lp-norm\", 0.5, 1], [\"SaltPepper\", 0.05]]],\n",
    "    [[\"Lp-norm\", 0.5, 2]],\n",
    "    [[\"Lp-norm\", 0.5, 3]],\n",
    "    [[\"Lp-norm\", 0.5, 4]],\n",
    "    [[\"Lp-norm\", 0.5, float('inf')]],\n",
    "    [[\"ContrastBrightness\", 0.9, 0.9]],\n",
    "    [[\"RotationFlip\", 0.3]],\n",
    "    [[\"SaltPepper\", 0.05]],\n",
    "    [[\"Gaussian\", 0.05], [\"Laplacian\", 0.05]],\n",
    "    [[[\"Gaussian\", 0.05], [\"Laplacian\", 0.05]]],\n",
    "    [[\"Gaussian\", 0.05], [\"Lp-norm\", 0.5, 1]],\n",
    "    [[\"Laplacian\", 0.05], [\"Lp-norm\", 0.5, 1]],\n",
    "    [[\"Lp-norm\", 0.5, 1], [\"Lp-norm\", 0.5, 2]],\n",
    "    [[\"Gaussian\", 0.05], [\"Laplacian\", 0.05], [\"Lp-norm\", 0.5, 1]],\n",
    "    [[\"Gaussian\", 0.05], [[\"Laplacian\", 0.05], [\"SaltPepper\", 0.05]]],\n",
    "    [[\"Gaussian\", 0.05], [[\"Lp-norm\", 0.5, 1], [\"ContrastBrightness\", 0.9, 0.9]]],\n",
    "    [[\"Laplacian\", 0.05], [[\"Lp-norm\", 0.5, 1], [\"RotationFlip\", 0.3]]],\n",
    "    [[[\"Gaussian\", 0.05], [\"SaltPepper\", 0.05]], [[\"Gaussian\", 0.05], [\"RotationFlip\", 0.3]]],\n",
    "    [[[\"Laplacian\", 0.05], [\"SaltPepper\", 0.05]], [[\"Laplacian\", 0.05], [\"RotationFlip\", 0.3]]],\n",
    "    [[[\"Lp-norm\", 0.5, 1], [\"SaltPepper\", 0.05]], [[\"Lp-norm\", 0.5, 1], [\"RotationFlip\", 0.3]]],\n",
    "    [[[\"Gaussian\", 0.05], [\"SaltPepper\", 0.05]], [[\"Gaussian\", 0.05], [\"RotationFlip\", 0.3]], [[\"Lp-norm\", 0.5, 1], [\"SaltPepper\", 0.05]], [[\"Lp-norm\", 0.5, 1], [\"RotationFlip\", 0.3]]],\n",
    "    [[[\"Gaussian\", 0.05], [\"SaltPepper\", 0.05]], [[\"Gaussian\", 0.05], [\"RotationFlip\", 0.3]], [[\"Lp-norm\", 0.5, 1], [\"SaltPepper\", 0.05]], [[\"Lp-norm\", 0.5, 1], [\"RotationFlip\", 0.3]], [[\"Laplacian\", 0.05], [\"SaltPepper\", 0.05]], [[\"Laplacian\", 0.05], [\"RotationFlip\", 0.3]]]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_history = []\n",
    "\n",
    "def display_test_history(test_history):\n",
    "    for i in range(len(test_history)):\n",
    "        test = test_history[i]\n",
    "        num_p = len(test['perturbations'])\n",
    "        io = test['include_original']\n",
    "        shuffle = test['shuffle']\n",
    "        training_time = test['training_time']\n",
    "        baseline = test['baseline_accuracy']\n",
    "        adversarial = test['adversarial_accuracy']\n",
    "        adv_str = f\"{adversarial[0]*100}/{adversarial[1]*100}/{adversarial[2]*100}/{adversarial[3]*100}\"\n",
    "        print(f\"Test {i}: Perturbations ({num_p}), Original ({io}), Shuffle ({shuffle}), Training Time ({training_time}s), Baseline ({baseline*100}%), Adversarial ({adv_str}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model with perturbations:\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "for perturbation_description in perturbation_tests:\n",
    "    perturbations = create_perturbations(perturbation_description)\n",
    "    include_original = perturbation_description == []\n",
    "    shuffle = True\n",
    "    multiplicity = len(perturbation_description) + int(include_original)\n",
    "\n",
    "    # Create REPResNet Model with multiplicity applied\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    ## Model is structured after ResNet50\n",
    "    model = REPResNet(Bottleneck, [3, 4, 5, 3], num_classes=10, multiplicity=multiplicity).to(device)\n",
    "\n",
    "    lr = 0.001\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr, weight_decay=0.0001)\n",
    "\n",
    "    preprocessing_defense = REPPreprocessor(perturbations, include_original, shuffle)\n",
    "    classifier = PyTorchClassifier(\n",
    "        model=model,\n",
    "        loss=criterion,\n",
    "        optimizer=optimizer,\n",
    "        input_shape=(3*multiplicity, 32, 32),\n",
    "        nb_classes=10,\n",
    "        preprocessing_defences=[preprocessing_defense]\n",
    "    )\n",
    "\n",
    "    batch_size = 128\n",
    "    super_epochs = 5\n",
    "    epochs_per = 10\n",
    "    print(f\"Training model with perturbations:\")\n",
    "    print(perturbation_description)\n",
    "    training_start = time.time()\n",
    "    for epoch in range(super_epochs):\n",
    "        classifier.fit(x_train, y_train, batch_size=batch_size, nb_epochs=epochs_per, verbose=False)\n",
    "        with torch.no_grad():\n",
    "            train_predictions = classifier.predict(x_train)\n",
    "            train_accuracy = np.sum(np.argmax(train_predictions, axis=1) == np.argmax(y_train, axis=1)) / len(y_train)\n",
    "            test_predictions = classifier.predict(x_test)\n",
    "            test_accuracy = np.sum(np.argmax(test_predictions, axis=1) == np.argmax(y_test, axis=1)) / len(y_test)\n",
    "            print(f\"Epoch {(epoch+1)*epochs_per}/{super_epochs*epochs_per} Complete After {int(time.time() - training_start)}s! Train Acc: {train_accuracy}, Test Acc: {test_accuracy}\")\n",
    "    total_time = time.time() - training_start\n",
    "\n",
    "    # Step 5: Evaluate the ART classifier on benign test examples\n",
    "    predictions = classifier.predict(x_test)\n",
    "    baseline_accuracy = np.sum(np.argmax(predictions, axis=1) == np.argmax(y_test, axis=1)) / len(y_test)\n",
    "    print(\"Accuracy on benign test examples: {}%\".format(baseline_accuracy * 100))\n",
    "\n",
    "    # Step 6: Generate adversarial test examples\n",
    "    attack = FastGradientMethod(estimator=classifier, eps=0.025)\n",
    "    x_test_adv1 = attack.generate(x=x_test)\n",
    "    predictions = classifier.predict(x_test_adv1)\n",
    "    adversarial_accuracy1 = np.sum(np.argmax(predictions, axis=1) == np.argmax(y_test, axis=1)) / len(y_test)\n",
    "    print(\"Accuracy on adversarial test examples (epsilon = 0.025): {}%\".format(adversarial_accuracy1 * 100))\n",
    "\n",
    "    attack = FastGradientMethod(estimator=classifier, eps=0.05)\n",
    "    x_test_adv2 = attack.generate(x=x_test)\n",
    "    predictions = classifier.predict(x_test_adv2)\n",
    "    adversarial_accuracy2 = np.sum(np.argmax(predictions, axis=1) == np.argmax(y_test, axis=1)) / len(y_test)\n",
    "    print(\"Accuracy on adversarial test examples (epsilon = 0.05): {}%\".format(adversarial_accuracy2 * 100))\n",
    "\n",
    "    attack = FastGradientMethod(estimator=classifier, eps=0.075)\n",
    "    x_test_adv3 = attack.generate(x=x_test)\n",
    "    predictions = classifier.predict(x_test_adv3)\n",
    "    adversarial_accuracy3 = np.sum(np.argmax(predictions, axis=1) == np.argmax(y_test, axis=1)) / len(y_test)\n",
    "    print(\"Accuracy on adversarial test examples (epsilon = 0.075): {}%\".format(adversarial_accuracy3 * 100))\n",
    "\n",
    "    attack = FastGradientMethod(estimator=classifier, eps=0.1)\n",
    "    x_test_adv4 = attack.generate(x=x_test)\n",
    "    predictions = classifier.predict(x_test_adv4)\n",
    "    adversarial_accuracy4 = np.sum(np.argmax(predictions, axis=1) == np.argmax(y_test, axis=1)) / len(y_test)\n",
    "    print(\"Accuracy on adversarial test examples (epsilon = 0.1): {}%\".format(adversarial_accuracy4 * 100))\n",
    "\n",
    "    test_history.append({'model': \"REPResNet-50\",\n",
    "                        'layers': [3, 4, 5, 3],\n",
    "                        'perturbations': perturbation_description,\n",
    "                        'include_original': include_original,\n",
    "                        'shuffle': shuffle,\n",
    "                        'loss': criterion,\n",
    "                        'lr': lr,\n",
    "                        'batch_size': batch_size,\n",
    "                        'epochs': int(super_epochs*epochs_per),\n",
    "                        'training_time': total_time,\n",
    "                        'baseline_accuracy': baseline_accuracy,\n",
    "                        'adversarial_accuracy': [adversarial_accuracy1, adversarial_accuracy2, adversarial_accuracy3, adversarial_accuracy4]})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test 0: Perturbations (2), Original (False), Shuffle (True), Training Time (208.2573003768921s), Baseline (29.160000000000004%), Adversarial (17.02/11.72/9.139999999999999/7.000000000000001%)\n"
     ]
    }
   ],
   "source": [
    "display_test_history(test_history=test_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data saved to ../../notebooks/experiment_log/cifar_100_round_2_training_results.csv successfully.\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "\n",
    "def save_to_csv(data, filename):\n",
    "    if not data:\n",
    "        return\n",
    "\n",
    "    # Extract the keys from the first dictionary as headers\n",
    "    headers = list(data[0].keys())\n",
    "\n",
    "    with open(filename, 'w', newline='') as csvfile:\n",
    "        writer = csv.DictWriter(csvfile, fieldnames=headers)\n",
    "\n",
    "        # Write the headers\n",
    "        writer.writeheader()\n",
    "\n",
    "        # Write each dictionary as a row in the CSV file\n",
    "        for item in data:\n",
    "            writer.writerow(item)\n",
    "\n",
    "    print(f\"Data saved to {filename} successfully.\")\n",
    "\n",
    "save_to_csv(test_history, ROOT + \"notebooks/experiment_log/cifar_10_resnet_round_1_training_results.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyTorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
